behaviors:
  Hunter:
    trainer_type: ppo
    hyperparameters:
      batch_size: 512
      buffer_size: 20580
      learning_rate: 0.0003
      beta: 0.003
      epsilon: 0.2
      lambd: 0.95
      num_epoch: 3
      learning_rate_schedule: linear
    network_settings:
      normalize: true
      hidden_units: 256
      num_layers: 2
      vis_encode_type: simple
    reward_signals:
      extrinsic:
        gamma: 0.99
        strength: 1.0
    keep_checkpoints: 2
    max_steps: 3000000
    time_horizon: 1024
    summary_freq: 10000
    threaded: true
    
curriculum:
  Hunter:
    measure: reward
    thresholds: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4]
    min_lesson_length: 200
    parameters:
      killRange: [9, 8.5, 8, 7.5, 7, 6.5, 6, 5.5, 5, 4.5, 4, 3.5, 3, 2.5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,2, 2, 2, 2, 2, 2, 2, 2, 2, 2,2, 2, 2, 2, 2,  2, 2, 2, 2, 2,2, 2, 2, 2, 2,2, 2, 2, 2, 2,2, 2, 2, 2, 2,2, 2, 2, 2, 2,2, 2, 2, 2, 2,2, 2, 2, 2, 2,2, 2, 2]
      praySpeed: [0, 0, 200, 200, 250, 250, 300, 310, 320, 330, 340, 350, 360, 370, 380, 390, 400, 410, 420, 430, 440, 450, 460, 470, 480, 490, 500, 510, 520, 530, 540, 550, 560, 570, 580, 590, 600, 610, 620, 630, 640, 650, 660, 670, 680, 690, 700, 710, 720, 730, 740, 750, 760, 770, 780, 790, 800, 810, 820, 830, 840, 850, 860, 870, 880, 890, 900, 910, 920, 930, 940, 950, 960, 970, 980, 990, 1000]